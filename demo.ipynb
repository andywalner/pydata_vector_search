{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Hudi + Lance Demo: Intelligent Recruitment Platform\n",
    "**(Hybrid Search + Analytics on the Lakehouse)**\n",
    "\n",
    "One table. Three query patterns. Zero data copying.\n",
    "\n",
    "1. Load real job postings from HuggingFace\n",
    "2. Ingest into a Hudi table with Lance vector embeddings\n",
    "3. **Vector Search** â€” match a resume by meaning\n",
    "4. **Hybrid Search** â€” add business constraints (SQL + vectors)\n",
    "5. **Analytics** â€” executive dashboard on the same data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.types import *\n",
    "from datasets import load_dataset\n",
    "import shutil, os, sys\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sentence_transformers import SentenceTransformer\n",
    "\n",
    "TABLE_PATH = \"/tmp/hudi_recruiting_lake\"\n",
    "TABLE_NAME = \"job_market\"\n",
    "EMBEDDING_MODEL = \"all-MiniLM-L6-v2\"\n",
    "\n",
    "# Spark/Lance emit log lines with surrogate characters that break\n",
    "# Jupyter's JSON serializer. Wrap both streams to sanitize them.\n",
    "class _SafeStream:\n",
    "    def __init__(self, stream):\n",
    "        self._stream = stream\n",
    "    def write(self, s):\n",
    "        return self._stream.write(s.encode(\"utf-8\", errors=\"replace\").decode(\"utf-8\"))\n",
    "    def flush(self):\n",
    "        return self._stream.flush()\n",
    "    def __getattr__(self, name):\n",
    "        return getattr(self._stream, name)\n",
    "\n",
    "sys.stdout = _SafeStream(sys.stdout)\n",
    "sys.stderr = _SafeStream(sys.stderr)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Start Spark with Hudi + Lance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "26/02/13 11:32:51 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n",
      "Setting default log level to \"WARN\".\n",
      "To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ“ Spark 3.5.3 ready with Hudi extensions.\n"
     ]
    }
   ],
   "source": [
    "spark = (SparkSession.builder.appName(\"Recruiting-Lakehouse\")\n",
    "    .config(\"spark.serializer\", \"org.apache.spark.serializer.KryoSerializer\")\n",
    "    .config(\"spark.sql.extensions\", \"org.apache.spark.sql.hudi.HoodieSparkSessionExtension\")\n",
    "    .config(\"spark.sql.catalog.spark_catalog\", \"org.apache.spark.sql.hudi.catalog.HoodieCatalog\")\n",
    "    .config(\"spark.driver.memory\", \"4g\")\n",
    "    .config(\"spark.ui.showConsoleProgress\", \"false\")\n",
    "    .getOrCreate())\n",
    "\n",
    "spark.sparkContext.setLogLevel(\"ERROR\")\n",
    "\n",
    "print(f\"\\u2713 Spark {spark.version} ready with Hudi extensions.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Load Real Job Postings from HuggingFace\n",
    "\n",
    "~3k data science job descriptions from [nathansutton/data-science-job-descriptions](https://huggingface.co/datasets/nathansutton/data-science-job-descriptions)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Repo card metadata block was not found. Setting CardData to empty.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ“ Loaded 2921 job postings from 969 companies.\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>job_id</th>\n",
       "      <th>company</th>\n",
       "      <th>title</th>\n",
       "      <th>job_description</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>job_0000</td>\n",
       "      <td>Altoida</td>\n",
       "      <td>Data Science Director</td>\n",
       "      <td>\\n\\n\\n\\nAltoida is a pioneer in developing dig...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>job_0001</td>\n",
       "      <td>Veeva Systems</td>\n",
       "      <td>Senior Data Scientist</td>\n",
       "      <td>\\n\\n\\nVeeva Systems is a mission-driven organi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>job_0002</td>\n",
       "      <td>Slack</td>\n",
       "      <td>Staff Data Scientist</td>\n",
       "      <td>\\nTo get the best candidate experience, please...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>job_0003</td>\n",
       "      <td>Pinterest</td>\n",
       "      <td>Sr Staff Data Scientist Ecosystem</td>\n",
       "      <td>\\n\\nAbout Pinterest:\\nMillions of people acros...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>job_0004</td>\n",
       "      <td>Pinterest</td>\n",
       "      <td>Staff Data Scientist Growth</td>\n",
       "      <td>\\n\\nAbout Pinterest:\\nMillions of people acros...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>job_0005</td>\n",
       "      <td>Pinterest</td>\n",
       "      <td>Staff Data Scientist Browse Discovery</td>\n",
       "      <td>\\n\\nAbout Pinterest:\\nMillions of people acros...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>job_0006</td>\n",
       "      <td>Pinterest</td>\n",
       "      <td>Sr Data Scientist Search</td>\n",
       "      <td>\\n\\nAbout Pinterest:\\nMillions of people acros...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>job_0007</td>\n",
       "      <td>Pinterest</td>\n",
       "      <td>Sr Data Scientist Growth</td>\n",
       "      <td>\\n\\nAbout Pinterest:\\nMillions of people acros...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>job_0008</td>\n",
       "      <td>Proofpoint</td>\n",
       "      <td>Senior Data Scientist</td>\n",
       "      <td>\\nIt's fun to work in a company where people t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>job_0009</td>\n",
       "      <td>Comcast</td>\n",
       "      <td>Lead Data Scientist</td>\n",
       "      <td>\\n\\nJob Summary\\nThe Data Science team builds ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     job_id        company                                  title  \\\n",
       "0  job_0000        Altoida                  Data Science Director   \n",
       "1  job_0001  Veeva Systems                  Senior Data Scientist   \n",
       "2  job_0002          Slack                   Staff Data Scientist   \n",
       "3  job_0003      Pinterest      Sr Staff Data Scientist Ecosystem   \n",
       "4  job_0004      Pinterest            Staff Data Scientist Growth   \n",
       "5  job_0005      Pinterest  Staff Data Scientist Browse Discovery   \n",
       "6  job_0006      Pinterest               Sr Data Scientist Search   \n",
       "7  job_0007      Pinterest               Sr Data Scientist Growth   \n",
       "8  job_0008     Proofpoint                  Senior Data Scientist   \n",
       "9  job_0009        Comcast                    Lead Data Scientist   \n",
       "\n",
       "                                     job_description  \n",
       "0  \\n\\n\\n\\nAltoida is a pioneer in developing dig...  \n",
       "1  \\n\\n\\nVeeva Systems is a mission-driven organi...  \n",
       "2  \\nTo get the best candidate experience, please...  \n",
       "3  \\n\\nAbout Pinterest:\\nMillions of people acros...  \n",
       "4  \\n\\nAbout Pinterest:\\nMillions of people acros...  \n",
       "5  \\n\\nAbout Pinterest:\\nMillions of people acros...  \n",
       "6  \\n\\nAbout Pinterest:\\nMillions of people acros...  \n",
       "7  \\n\\nAbout Pinterest:\\nMillions of people acros...  \n",
       "8  \\nIt's fun to work in a company where people t...  \n",
       "9  \\n\\nJob Summary\\nThe Data Science team builds ...  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ds = load_dataset(\"nathansutton/data-science-job-descriptions\", split=\"train\")\n",
    "\n",
    "jobs_data = []\n",
    "for i, row in enumerate(ds):\n",
    "    jobs_data.append({\n",
    "        \"job_id\": f\"job_{i:04d}\",\n",
    "        \"company\": row[\"company\"],\n",
    "        \"title\": row[\"title\"],\n",
    "        \"job_description\": row[\"job_description\"],\n",
    "        \"text_for_vector\": f\"{row['title']} {row['job_description']}\"\n",
    "    })\n",
    "\n",
    "companies = set(r[\"company\"] for r in jobs_data)\n",
    "print(f\"\\u2713 Loaded {len(jobs_data)} job postings from {len(companies)} companies.\\n\")\n",
    "\n",
    "preview = pd.DataFrame(jobs_data, columns=[\"job_id\", \"company\", \"title\", \"job_description\"])\n",
    "preview[\"job_description\"] = preview[\"job_description\"].str[:80] + \"...\"\n",
    "preview.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Embed & Ingest into the Lakehouse\n",
    "\n",
    "We embed every job description into a 384-dim vector, then write structured fields **and** embeddings into a single Hudi table using the Lance file format."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cbc588bb272e44c0aab32f2aa421794e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/92 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ“ Generated 2921 embeddings (dim=384).\n",
      "  Each embedding is built from: title + job_description\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>job_id</th>\n",
       "      <th>title</th>\n",
       "      <th>job_description</th>\n",
       "      <th>embedding</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>job_0000</td>\n",
       "      <td>Data Science Director</td>\n",
       "      <td>\\n\\n\\n\\nAltoida is a pioneer in developing dig...</td>\n",
       "      <td>[-0.030186746269464493, -0.07726149260997772, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>job_0001</td>\n",
       "      <td>Senior Data Scientist</td>\n",
       "      <td>\\n\\n\\nVeeva Systems is a mission-driven organi...</td>\n",
       "      <td>[-0.07847969979047775, -0.023534078150987625, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>job_0002</td>\n",
       "      <td>Staff Data Scientist</td>\n",
       "      <td>\\nTo get the best candidate experience, please...</td>\n",
       "      <td>[-0.024468308314681053, -0.06033605337142944, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>job_0003</td>\n",
       "      <td>Sr Staff Data Scientist Ecosystem</td>\n",
       "      <td>\\n\\nAbout Pinterest:\\nMillions of people acros...</td>\n",
       "      <td>[-0.017895415425300598, -0.13528017699718475, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>job_0004</td>\n",
       "      <td>Staff Data Scientist Growth</td>\n",
       "      <td>\\n\\nAbout Pinterest:\\nMillions of people acros...</td>\n",
       "      <td>[-0.021268101409077644, -0.14506541192531586, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>job_0005</td>\n",
       "      <td>Staff Data Scientist Browse Discovery</td>\n",
       "      <td>\\n\\nAbout Pinterest:\\nMillions of people acros...</td>\n",
       "      <td>[-0.041841521859169006, -0.14577853679656982, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>job_0006</td>\n",
       "      <td>Sr Data Scientist Search</td>\n",
       "      <td>\\n\\nAbout Pinterest:\\nMillions of people acros...</td>\n",
       "      <td>[-0.04083168879151344, -0.12358294427394867, 0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>job_0007</td>\n",
       "      <td>Sr Data Scientist Growth</td>\n",
       "      <td>\\n\\nAbout Pinterest:\\nMillions of people acros...</td>\n",
       "      <td>[-0.02691471204161644, -0.11413008719682693, 0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>job_0008</td>\n",
       "      <td>Senior Data Scientist</td>\n",
       "      <td>\\nIt's fun to work in a company where people t...</td>\n",
       "      <td>[-0.07257407158613205, -0.014052029699087143, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>job_0009</td>\n",
       "      <td>Lead Data Scientist</td>\n",
       "      <td>\\n\\nJob Summary\\nThe Data Science team builds ...</td>\n",
       "      <td>[-0.0638699010014534, -0.058765701949596405, 0...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     job_id                                  title  \\\n",
       "0  job_0000                  Data Science Director   \n",
       "1  job_0001                  Senior Data Scientist   \n",
       "2  job_0002                   Staff Data Scientist   \n",
       "3  job_0003      Sr Staff Data Scientist Ecosystem   \n",
       "4  job_0004            Staff Data Scientist Growth   \n",
       "5  job_0005  Staff Data Scientist Browse Discovery   \n",
       "6  job_0006               Sr Data Scientist Search   \n",
       "7  job_0007               Sr Data Scientist Growth   \n",
       "8  job_0008                  Senior Data Scientist   \n",
       "9  job_0009                    Lead Data Scientist   \n",
       "\n",
       "                                     job_description  \\\n",
       "0  \\n\\n\\n\\nAltoida is a pioneer in developing dig...   \n",
       "1  \\n\\n\\nVeeva Systems is a mission-driven organi...   \n",
       "2  \\nTo get the best candidate experience, please...   \n",
       "3  \\n\\nAbout Pinterest:\\nMillions of people acros...   \n",
       "4  \\n\\nAbout Pinterest:\\nMillions of people acros...   \n",
       "5  \\n\\nAbout Pinterest:\\nMillions of people acros...   \n",
       "6  \\n\\nAbout Pinterest:\\nMillions of people acros...   \n",
       "7  \\n\\nAbout Pinterest:\\nMillions of people acros...   \n",
       "8  \\nIt's fun to work in a company where people t...   \n",
       "9  \\n\\nJob Summary\\nThe Data Science team builds ...   \n",
       "\n",
       "                                           embedding  \n",
       "0  [-0.030186746269464493, -0.07726149260997772, ...  \n",
       "1  [-0.07847969979047775, -0.023534078150987625, ...  \n",
       "2  [-0.024468308314681053, -0.06033605337142944, ...  \n",
       "3  [-0.017895415425300598, -0.13528017699718475, ...  \n",
       "4  [-0.021268101409077644, -0.14506541192531586, ...  \n",
       "5  [-0.041841521859169006, -0.14577853679656982, ...  \n",
       "6  [-0.04083168879151344, -0.12358294427394867, 0...  \n",
       "7  [-0.02691471204161644, -0.11413008719682693, 0...  \n",
       "8  [-0.07257407158613205, -0.014052029699087143, ...  \n",
       "9  [-0.0638699010014534, -0.058765701949596405, 0...  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = SentenceTransformer(EMBEDDING_MODEL)\n",
    "embeddings = model.encode([r[\"text_for_vector\"] for r in jobs_data], show_progress_bar=True)\n",
    "\n",
    "for i, row in enumerate(jobs_data):\n",
    "    row[\"embedding\"] = embeddings[i].tolist()\n",
    "\n",
    "print(f\"\\u2713 Generated {len(embeddings)} embeddings (dim={len(embeddings[0])}).\")\n",
    "print(f\"  Each embedding is built from: title + job_description\\n\")\n",
    "\n",
    "preview = pd.DataFrame(jobs_data, columns=[\"job_id\", \"title\", \"job_description\", \"embedding\"])\n",
    "preview[\"job_description\"] = preview[\"job_description\"].str[:60] + \"...\"\n",
    "preview[\"embedding\"] = preview[\"embedding\"].apply(lambda v: str(v[:3])[:-1] + \", ...]\")\n",
    "preview.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# WARNING: Unable to get Instrumentation. Dynamic Attach failed. You may add this JAR as -javaagent manually, or supply -Djdk.attach.allowAttachSelf\n",
      "# WARNING: Unable to attach Serviceability Agent. Unable to attach even with module exceptions: [org.apache.hudi.org.openjdk.jol.vm.sa.SASupportException: Sense failed., org.apache.hudi.org.openjdk.jol.vm.sa.SASupportException: Sense failed., org.apache.hudi.org.openjdk.jol.vm.sa.SASupportException: Sense failed.]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[90m[\u001b[0m2026-02-13T16:33:26Z \u001b[33mWARN \u001b[0m lance_file::v2::writer\u001b[90m]\u001b[0m You have requested an unstable format version.  Files written with this format version may not be readable in the future!  This is a development feature and should only be used for experimentation and never for production data.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ“ Ingested 2921 jobs into Hudi table at /tmp/hudi_recruiting_lake\n"
     ]
    }
   ],
   "source": [
    "schema = StructType([\n",
    "    StructField(\"job_id\", StringType(), False),\n",
    "    StructField(\"company\", StringType(), False),\n",
    "    StructField(\"title\", StringType(), False),\n",
    "    StructField(\"job_description\", StringType(), False),\n",
    "    StructField(\"text_for_vector\", StringType(), False),\n",
    "    StructField(\"embedding\", ArrayType(FloatType()), False),\n",
    "])\n",
    "\n",
    "if os.path.exists(TABLE_PATH):\n",
    "    shutil.rmtree(TABLE_PATH)\n",
    "\n",
    "df = spark.createDataFrame(jobs_data, schema=schema)\n",
    "\n",
    "hudi_options = {\n",
    "    \"hoodie.table.name\": TABLE_NAME,\n",
    "    \"hoodie.datasource.write.recordkey.field\": \"job_id\",\n",
    "    \"hoodie.datasource.write.partitionpath.field\": \"company\",\n",
    "    \"hoodie.datasource.write.table.type\": \"COPY_ON_WRITE\",\n",
    "    \"hoodie.datasource.write.operation\": \"bulk_insert\",\n",
    "    \"hoodie.table.base.file.format\": \"lance\",\n",
    "    \"hoodie.write.record.merge.custom.implementation.classes\": \"org.apache.hudi.DefaultSparkRecordMerger\"\n",
    "}\n",
    "\n",
    "df.write.format(\"hudi\").options(**hudi_options).mode(\"overwrite\").save(TABLE_PATH)\n",
    "print(f\"\\u2713 Ingested {len(jobs_data)} jobs into Hudi table at {TABLE_PATH}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## 4. Vector Search â€” \"Upload\" a Resume\n",
    "\n",
    "A candidate uploads their resume. They have experience in **product growth, A/B testing, and experimentation** â€” but the resume never uses the exact job title *\"Data Scientist Growth.\"* Can the system find the right roles anyway?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ðŸ“„ Resume Uploaded:\n",
      "EXPERIENCE:\n",
      "- 4 years driving product growth through data science and experimentation.\n",
      "- Built A/B testing frameworks and analyzed user funnels to optimize conversion.\n",
      "- Led causal inference studies measuring the impact of new product features.\n",
      "- Python, SQL, Bayesian statistics, and machine learning for growth modeling.\n"
     ]
    }
   ],
   "source": [
    "resume_text = \"\"\"\n",
    "EXPERIENCE:\n",
    "- 4 years driving product growth through data science and experimentation.\n",
    "- Built A/B testing frameworks and analyzed user funnels to optimize conversion.\n",
    "- Led causal inference studies measuring the impact of new product features.\n",
    "- Python, SQL, Bayesian statistics, and machine learning for growth modeling.\n",
    "\"\"\"\n",
    "\n",
    "print(f\"\\U0001F4C4 Resume Uploaded:\\n{resume_text.strip()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "resume_vector = model.encode([resume_text])[0].tolist()\nspark.createDataFrame([(resume_vector,)], [\"q_vec\"]).createOrReplaceTempView(\"query_input\")\n\n# Read the full table for joining (vector search can misalign non-vector columns)\nspark.read.format(\"hudi\").load(TABLE_PATH).createOrReplaceTempView(\"jobs_table\")\n\nmatches_df = spark.sql(f\"\"\"\n    SELECT j.title, j.company, j.job_description, round(1 - v._distance, 2) as score\n    FROM hudi_vector_search(\n        '{TABLE_PATH}', 'embedding', (SELECT q_vec FROM query_input), 10, 'cosine'\n    ) v\n    JOIN jobs_table j ON v.job_id = j.job_id\n\"\"\").toPandas()\n\nmatches_df[\"job_description\"] = matches_df[\"job_description\"].str.strip().str[:100] + \"...\"\n\nprint(\"\\U0001F50E Top Semantic Matches:\\n\")\nmatches_df"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The resume never mentions *\"Data Scientist\"* or *\"Growth\"* as a job title â€” but vector search finds growth-focused roles by **meaning**, not keywords.\n",
    "\n",
    "---\n",
    "## 5. Hybrid Search â€” Add Business Constraints\n",
    "\n",
    "The candidate says: *\"I specifically want to work at Reddit.\"*\n",
    "\n",
    "We combine the **same vector search** with a standard SQL `WHERE` clause. Vector + SQL in one query."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# Post-filter approach: fetch a wide vector search window, then apply SQL filters.\n# hudi_vector_search() operates on the full vector index and doesn't yet support\n# predicate pushdown â€” so we retrieve broadly and filter after.\n# Future optimization: push filters directly into the vector index scan.\n\nhybrid_df = spark.sql(f\"\"\"\n    SELECT j.title, j.company, j.job_description, round(1 - v._distance, 2) as score\n    FROM hudi_vector_search(\n        '{TABLE_PATH}', 'embedding', (SELECT q_vec FROM query_input), 3000, 'cosine'\n    ) v\n    JOIN jobs_table j ON v.job_id = j.job_id\n    WHERE j.company = 'Reddit'\n    ORDER BY score DESC\n    LIMIT 5\n\"\"\").toPandas()\n\nhybrid_df[\"job_description\"] = hybrid_df[\"job_description\"].str.strip().str[:100] + \"...\"\n\nprint(\"\\U0001F50E Hybrid Matches (Reddit only):\\n\")\nhybrid_df"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Same Hudi table. Same vector index. Just added a SQL filter.\n",
    "\n",
    "---\n",
    "## 6. Analytics Dashboard\n",
    "\n",
    "Now we switch hats â€” we're an analyst on the job platform team. Which companies are hiring the most? What roles dominate the market? We query the **exact same table**. No ETL to a separate warehouse."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "spark.read.format(\"hudi\").load(TABLE_PATH).createOrReplaceTempView(\"jobs_table\")\n",
    "\n",
    "company_df = spark.sql(\"\"\"\n",
    "    SELECT company, count(*) as job_count\n",
    "    FROM jobs_table GROUP BY company\n",
    "    ORDER BY job_count DESC LIMIT 15\n",
    "\"\"\").toPandas()\n",
    "\n",
    "title_df = spark.sql(\"\"\"\n",
    "    SELECT title, count(*) as title_count\n",
    "    FROM jobs_table GROUP BY title\n",
    "    ORDER BY title_count DESC LIMIT 15\n",
    "\"\"\").toPandas()\n",
    "\n",
    "fig, axes = plt.subplots(1, 2, figsize=(15, 5))\n",
    "\n",
    "axes[0].barh(company_df[\"company\"], company_df[\"job_count\"], color=\"green\")\n",
    "axes[0].set_title(\"Hiring Activity: Postings by Company\")\n",
    "axes[0].set_xlabel(\"Number of Postings\")\n",
    "axes[0].invert_yaxis()\n",
    "\n",
    "axes[1].barh(title_df[\"title\"], title_df[\"title_count\"], color=\"skyblue\")\n",
    "axes[1].set_title(\"Most Common Data Science Roles\")\n",
    "axes[1].set_xlabel(\"Number of Postings\")\n",
    "axes[1].invert_yaxis()\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(\"\\u2713 Dashboard generated from the same Hudi table.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "**One table. Vector search, hybrid search, and analytics. No data copying, no separate vector database.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "spark.stop()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}